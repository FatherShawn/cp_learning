# Overview
This repository contains the code written to support the research for my thesis 
_Finding Latent Features in Internet Censorship Data_. Documentation in markdown
which has been generated from the docstrings within each python module
may be found in the docs directory.  Links are given below.  

# Documentation

- [ae_processor](https://github.com/FatherShawn/cp_learning/blob/main/docs/ae_processor.md)
- [autoencoder](https://github.com/FatherShawn/cp_learning/blob/main/docs/autoencoder.md)
- [blockpage](https://github.com/FatherShawn/cp_learning/blob/main/docs/blockpage.md)
- [check_meta](https://github.com/FatherShawn/cp_learning/blob/main/docs/check_meta.md)
- [cp_dataset](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_dataset.md)
- [cp_flatten](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_flatten.md)
- [cp_flatten_processor](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_flatten_processor.md)
- [cp_image_data](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_image_data.md)
- [cp_image_dataset](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_image_dataset.md)
- [cp_image_reprocessor](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_image_reprocessor.md)
- [cp_latent_classifier](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_latent_classifier.md)
- [cp_tokenized_data](https://github.com/FatherShawn/cp_learning/blob/main/docs/cp_tokenized_data.md)
- [densenet](https://github.com/FatherShawn/cp_learning/blob/main/docs/densenet.md)
- [dn_processor](https://github.com/FatherShawn/cp_learning/blob/main/docs/dn_processor.md)
- [nparray2png](https://github.com/FatherShawn/cp_learning/blob/main/docs/nparray2png.md)